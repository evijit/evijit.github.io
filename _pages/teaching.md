---
layout: page
permalink: /teaching/
title: Teaching
description:
nav: true
nav_order: 5
---

## Fall 2023
### CS 4973-05 Responsible Machine Learning

#### Course description: 
In today's world, machine learning (ML) models have proliferated different real-world applications, and responsibly deploying them is crucial to ensure their positive impact on society. This course is designed for senior computer science undergraduate students interested in exploring the ethical challenges and responsibilities of creating and deploying ML models. Throughout the course, students will learn about the various types of biases that can exist in ML models, methods for uncovering these biases via auditing, and algorithmic fairness techniques to mitigate them. The course will also delve into emerging ethical issues related to generative text and image models and discuss good governance of the AI landscape, covering both centralized regulatory efforts and decentralized defense mechanisms against problematic AI. Through a project component, students will have the opportunity to apply what they learn in class to a real-world scenario and gain hands-on experience in developing responsible ML models. By completing this course, students will become responsible AI practitioners who can create ethical and fair AI systems that benefit society.

#### Requirements: 
Knowledge of Python and ML fundamentals (DS 3000 or equivalent)

#### Syllabus:

{:class="table table-bordered"}
| **Date** | **Topic** | **Readings (before class)** | **Homework**
|--|--|--|--|
| **Thu, 9/7** | [Introduction to Course](https://evijit.io/materials/Lecture_1_Introduction.pdf) | - | - |
| **Tue, 9/12** | [Machine Learning - Refresher](https://evijit.io/materials/Lecture_2_ Machine_Learning_Basics.pdf) | [1] [Machine learning: Trends, perspectives, and prospects](https://www.cs.cmu.edu/~tom/pubs/Science-ML-2015.pdf) |  [Overleaf](https://www.overleaf.com/read/ftxshfbpkxbk) |
| **Thu, 9/14** | Setting up ML stack, basic ML coding in class | [1] (Optional) [How NLP Cracked Transfer Learning](https://jalammar.github.io/illustrated-bert/) | [Notebook](https://evijit.io/materials/ds_intro.ipynb) |
| **Tue, 9/19** | [Algorithmic Fairness - Intro](https://evijit.io/materials/Lecture_3_ Algorithmic_Fairness_Basics.pdf)  | [1] [Bias detectives: the researchers striving to make algorithms fair](https://courses.cs.duke.edu/spring20/compsci342/netid/readings/nature-algorithmic-bias.pdf) - R. Courtland <br> [2] (Optional) [A Survey on Bias and Fairness in Machine Learning](https://arxiv.org/pdf/1908.09635.pdf) - Mehrabi et. al |  [Overleaf](https://www.overleaf.com/read/rvdjbyjkktcg)  |
| **Thu, 9/21** | [Bias in the Wild](https://evijit.io/materials/Lecture_4_Bias_In_The_Wild.pdf) | [1] [Can you make AI fairer than a judge? Play our courtroom algorithm game](https://www.technologyreview.com/2019/10/17/75285/ai-fairer-than-judge-criminal-risk-assessment-algorithm/) - MIT Tech Review <br> [2] [Image Cropping on Twitter: Fairness Metrics, their Limitations, and the Importance of Representation, Design, and Agency](https://arxiv.org/pdf/2105.08667.pdf) - Yee et. al |[Notebook](https://colab.research.google.com/drive/1_SpLPRweuZ-3xWJSYmOD0H-LXdaCcEiH#scrollTo=KbHf3AYwO0Xw) |
| **Tue, 9/26** | [ML Fairness in contexts beyond the US](https://evijit.io/materials/Lecture_5_Fairness_in_Other_Cultures.pdf)  | [1] [Re-imagining Algorithmic Fairness in India and Beyond](https://arxiv.org/pdf/2101.09995.pdf) - Sambasivan et. al | [Overleaf](https://www.overleaf.com/read/zbtrrypygxrz) |
| **Thu, 9/28** | [Value Sensitive Design (Guest Lecture - Prof. Vance Ricks)](https://evijit.io/materials/Ricks-ResponsibleMachineLearning-F2023.pdf) | [1] [Introduction to Value Sensitive Design](https://northeastern.instructure.com/files/23160452/) | [In Class Activity](https://docs.google.com/document/d/1qi9J7lLVM9AhsJaSpILQNQh4FjRnNLnn/edit?usp=sharing&ouid=104786704786764345519&rtpof=true&sd=true) |
| **Tue, 10/3** | [Model Explainability/Interpretability](https://evijit.io/materials/Lecture_6_Model_Interpretability.pdf)  | [1] [The Mythos of Model Interpretability](https://arxiv.org/pdf/1606.03490.pdf) | [Overleaf](https://www.overleaf.com/read/fzfbymhmhrjf) |
| **Thu, 10/5** | ML Explainability Coding Class  | - | [Notebook](https://colab.research.google.com/drive/11d_AnpF6ELJryZaBOwvFYm2xgqL8GiEW) |
| **Tue, 10/10** | [Algorithm Auditing Overview](https://evijit.io/materials/Lecture_7_Algorithm_Auditing_Overview.pdf)  | [1] [An Image of Society: Gender and Racial Representation and Impact in Image Search Results for Occupations](https://dl.acm.org/doi/10.1145/3449100)<br>[2] [Bias in Online Freelance Marketplaces: Evidence from TaskRabbit and Fiverr](https://dl.acm.org/doi/pdf/10.1145/2998181.2998327) |  |
| **Thu, 10/12** | [Algorithm Auditing Tutorial](https://evijit.io/materials/Lecture_8_Algorithm_Auditing_Tutorial.pdf)  | - | [Notebook](https://colab.research.google.com/drive/1w-BRt1A2MymKFefj98t6Orz59-ntiPBF) |
| **Tue, 10/17** | [Machine Learning Privacy](https://evijit.io/materials/Lecture_9_ML_Privacy.pdf)  | [1] [An Overview of Privacy in Machine Learning](https://arxiv.org/pdf/2005.08679.pdf) | [Overleaf](https://www.overleaf.com/read/pswsvxrnwggq) |
| **Thu, 10/19** | [AI Safety](https://evijit.io/materials/Lecture_10_AI_Safety.pdf)  | [1] [There are two factions working to prevent AI dangers. Here’s why they’re deeply divided.](https://www.vox.com/future-perfect/2022/8/10/23298108/ai-dangers-ethics-alignment-present-future-risk) | - |
| **Tue, 10/24** | [Generative AI Memorization (Guest Lecture - Matthew Jagielski)](https://evijit.io/materials/GenAI_Memorization_Guest_Lecture_Matthew.pdf)  | - | - |
| **Thu, 10/26** | [MIDTERM](https://evijit.io/materials/CS_4973_Responsible_ML_Midterm.pdf)  | - | - |
| **Tue, 10/31** | Term Project - Midterm Review  | - | - |
| **Thu 11/2** | [Algorithmic Debiasing Methods](https://evijit.io/materials/Lecture_12_Algorithmic_Debiasing.pdf)  | - | [Overleaf](https://www.overleaf.com/read/dshshdwvpvjn#06c821) |
| **Tue, 11/7** | [Fair ML in the Real World - Part 1](https://evijit.io/materials/Lecture_13_Real_World_Problems_Part1.pdf)  |  [1] [When Fair Ranking Meets Uncertain Inference](https://dl.acm.org/doi/pdf/10.1145/3404835.3462850)<br>[2] [Subverting Fair Image Search with Generative Adversarial Perturbations](https://dl.acm.org/doi/pdf/10.1145/3531146.3533128) | - |
| **Thu, 11/9** | [Fair ML in the Real World - Part 2](https://evijit.io/materials/Lecture_14_Real_World_Problems_Part2.pdf)  |  [1][When Fair Classification Meets Noisy Protected Attributes](https://arxiv.org/pdf/2307.03306.pdf) <br> [2][FairCanary: Rapid Continuous Explainable Fairness](https://arxiv.org/pdf/2106.07057.pdf) | [Notebook](https://colab.research.google.com/drive/1nGY70jcrQSESMBV1cfo__WfUNJerU3yb) |
| **Thu, 11/16** | [Critical Image Synthesis (Guest Lecture: Eryk Salvaggio)](https://docs.google.com/presentation/d/153qJsw7qj9sj_s98h6z58CVHVtptGTge9kmdPvRp-pg/edit?usp=sharing)  | [1] [This is how AI image generators see the world](https://www.washingtonpost.com/technology/interactive/2023/ai-generated-images-bias-racism-sexism-stereotypes/) <br> [2] [How to read an AI image](https://cyberneticforests.substack.com/p/how-to-read-an-ai-image)  | - |
| **Tue, 11/21** | [A (very lacking) tech policy primer (Guest Lecture: Johanna Gunawan)](https://evijit.io/materials/Johanna_Gunawan_Policy_Primer.pdf)  |  - | - |
| **Tue, 11/28** | [Lessons learned from running a privacy tech challenge (Guest Lecture: David Buckley)](https://evijit.io/materials/David_Buckley_CDEI_Guest_Lecture.pdf)  |  - | [Overleaf](https://www.overleaf.com/read/bcqpwgkmcbgb#04beb3) |
| **Thu, 11/30** | [Participatory Methods and Community Actions for Responsible ML](https://evijit.io/materials/Lecture_15_Participatory_Approaches_Community_Action.pdf)  |  - | - |