<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Avijit Ghosh  </title>
    <meta name="author" content="Avijit Ghosh  ">
    <meta name="description" content="Applied Policy Researcher, ML and Society, Hugging Face.
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Libre+Franklin&amp;display=swap" rel="stylesheet">

    <!-- Facebook Meta Tags -->
    <meta property="og:url" content="https://evijit.io">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Avijit Ghosh ">
    <meta property="og:description" content="Applied Policy Researcher, ML and Society, Hugging Face.">
    <meta property="og:image" content="https://evijit.io/assets/img/prof_pic.jpg">

    <!-- Twitter Meta Tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta property="twitter:domain" content="evijit.io">
    <meta property="twitter:url" content="https://evijit.io">
    <meta name="twitter:title" content="Avijit Ghosh ">
    <meta name="twitter:description" content="Applied Policy Researcher, ML and Society, Hugging Face.">
    <meta name="twitter:image" content="https://evijit.io/assets/img/prof_pic.jpg">


    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/all.min.css" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Libre+Franklin:100,300,400,500,700|Material+Icons">
    <link rel="shortcut icon" type="image/x-icon" href="assets/img/favicon.ico">
    <link rel="icon" href="/assets/img/favicon.ico" sizes="32x32">
    <link rel="icon" href="/assets/img/favicon.ico" sizes="192x192">
    <link rel="apple-touch-icon-precomposed" href="/assets/img/favicon.ico">
    <meta name="msapplication-TileImage" content="/assets/img/favicon.ico">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.ico">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a>
              </li>
              <!-- <li class="nav-item"><a class="nav-link" href="https://evijit.io/assets/pdf/Avijit_CV.pdf">CV</a></li>  -->
              <!--  -->

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">Teaching</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/outreach/">Outreach</a>
              </li>
<li class="nav-item"><a class="nav-link" href="https://evijit.substack.com" rel="external nofollow noopener" target="_blank">Blog</a></li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fa-solid fa-moon"></i>
                  <i class="fa-solid fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title" style="margin-bottom: 20px;">
           <span class="font-weight-bold">Avijit Ghosh</span>  
          </h1>
        </header>

        <article style="font-size: 0.97em;">
          <div class="profile float-right" style=" margin-top: -20px; padding: 10px;">

                <figure>

  <picture>
    <!-- 
    <source 
        class="responsive-img-srcset"
        media="(max-width: 480px)" 
        srcset="/assets/img/prof_pic-480.webp"
      />
    <source 
        class="responsive-img-srcset"
        media="(max-width: 800px)" 
        srcset="/assets/img/prof_pic-800.webp"
      />
    <source 
        class="responsive-img-srcset"
        media="(max-width: 1400px)" 
        srcset="/assets/img/prof_pic-1400.webp"
      />
     -->

    <!-- Fallback to the original file -->
    <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
<!-- <h6 class="desc" style="text-align: center; margin-bottom: 20px;">Applied Policy Researcher, ML & Society, <a href='https://huggingface.co/">Hugging Face</a></h6> -->
              <div class="address" style="font-size: small; text-align: center; margin-top: -10px; margin-bottom: 10px;">
                
              </div>

              <!-- Social -->
              <div class="social">
                <div class="contact-icons" style="font-size:18px; letter-spacing: 3px;">
                              <!--<a href="mailto:%61%76%69%6A%69%74@%68%75%67%67%69%6E%67%66%61%63%65.%63%6F" title="email"><i class="fa-solid fa-envelope"></i></a>
             -->
            <!--<a href="https://github.com/evijit" title="GitHub"><i class="fa-brands fa-github"></i></a>
            <a href="https://www.linkedin.com/in/evijit" title="LinkedIn"><i class="fa-brands fa-linkedin"></i></a>
             -->
            <!--<a rel="me" href="https://hci.social/@evijitghosh" title="Mastodon"><i class="fa-brands fa-mastodon"></i></a>
             --><a href="https://x.com/evijitghosh" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a>
            
            <!--<a rel="me" href="https://hci.social/@evijitghosh" title="Mastodon"><i class="fa-brands fa-mastodon"></i></a>
             -->
            
            <a href="https://bsky.app/profile/evijit.io" title="Bluesky" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-bluesky"></i></a>
            <a href="https://www.linkedin.com/in/evijit" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin-in"></i></a>
            <a href="https://github.com/evijit" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a>
            <a href="https://scholar.google.com/citations?user=X9y2jJIAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-graduation-cap"></i></a>
            <a href="#" class="buttonmodal" title="email"><i class="fa-solid fa-envelope"></i></a>
             
           

                </div>

                <div class="contact-note">
                  
                </div>
                
              </div>
            </div>

          <div class="clearfix" style="text-align: justify">
            <p>Dr. Avijit Ghosh is an Applied Policy Researcher at <a href="https://huggingface.co/" rel="external nofollow noopener" target="_blank">Hugging Face 🤗</a> and an Associate Researcher in the <a href="https://infothreats.cse.uconn.edu/" rel="external nofollow noopener" target="_blank">RIET Lab at the University of Connecticut</a>. He works at the intersection of machine learning, ethics, and policy, aiming to implement fair ML algorithms into the real world. He has published and peer-reviewed several research papers in top ML and AI Ethics venues, and has organized academic workshops as a member of <a href="https://www.queerinai.com/" rel="external nofollow noopener" target="_blank">QueerInAI.</a> His work has been covered in the press, including articles in <a href="https://www.nytimes.com/2023/08/16/technology/ai-defcon-hackers.html" rel="external nofollow noopener" target="_blank">The New York Times</a>, <a href="https://www.forbes.com/sites/rashishrivastava/2023/09/01/ai-red-teams-google-nvidia-microsoft-meta/" rel="external nofollow noopener" target="_blank">Forbes</a>, <a href="https://www.theguardian.com/technology/2024/mar/16/ai-racism-chatgpt-gemini-bias" rel="external nofollow noopener" target="_blank">The Guardian</a>, <a href="https://www.propublica.org/article/facebook-ads-can-still-discriminate-against-women-and-older-workers-despite-a-civil-rights-settlement" rel="external nofollow noopener" target="_blank">Propublica</a>, <a href="https://www.wired.com/story/plaud-note-pin-ai-wearable/" rel="external nofollow noopener" target="_blank">Wired</a>, and the <a href="https://www.technologyreview.com/2025/03/24/1113647/why-handing-over-total-control-to-ai-agents-would-be-a-huge-mistake/" rel="external nofollow noopener" target="_blank">MIT Tech Review.</a> Dr. Ghosh has been an invited speaker as a Responsible AI expert, at various high impact events such as <a href="http://schedule.sxsw.com/2023/events/PP122773" rel="external nofollow noopener" target="_blank">SXSW</a>, <a href="https://www.linkedin.com/posts/evijit_last-friday-i-spoke-on-a-panel-called-concrete-activity-7296205559144300544-CZIr" rel="external nofollow noopener" target="_blank">MIT Sloan AI Conference</a> and the <a href="https://dec.yale.edu/programs/summit-on-state-ai-legislation-ssail" rel="external nofollow noopener" target="_blank">Summit on State AI Legislation</a>. He has also engaged with policymakers at various levels in the United States, United Kingdom, and Singapore. His research and outreach have led to real-world impact, such as helping <a href="https://apnews.com/article/technology-business-race-and-ethnicity-racial-injustice-artificial-intelligence-2fe8d3ef7008d299d9d810f0c0f7905d" rel="external nofollow noopener" target="_blank">shape regulation in New York City</a> and causing Facebook to <a href="https://about.fb.com/news/2022/06/expanding-our-work-on-ads-fairness/" rel="external nofollow noopener" target="_blank">remove their biased ad targeting algorithm.</a></p>

<p><a href="/assets/pdf/Avijit_CV.pdf" target="_blank"><b><u>View my CV here.</u></b></a></p>

          </div>

          <!-- News -->
          <h2><a href="/news/" style="color: inherit;">News</a></h2>          
          <div class="news">
            <div class="table-responsive" style="max-height: 45vw">
              <table class="table table-sm table-borderless">
               
                <tr>
                  <th scope="row">May 22, 2025</th>
                  <td>
                    I was on the <a href="https://podcasts.apple.com/us/podcast/were-not-ready-for-agentic-ai/id1751550186?i=1000709391707" rel="external nofollow noopener" target="_blank">Ethical Machines podcast with Reid Blackman</a>, to talk about AI, Agency, and how we need better scalable oversight mechanisms as the technical infrastructure around us starts to account for Agents!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 19, 2025</th>
                  <td>
                    I appeared in a <a href="https://www.marketplace.org/story/2025/05/19/can-ai-take-your-coding-job" rel="external nofollow noopener" target="_blank">segment by Matt Levin on NPR Marketplace</a>! I talk about how we are getting dependent on GenAI for coding (and other tasks) and how we need better structures to use them to aid and upskill us instead of replacing us.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 18, 2025</th>
                  <td>
                    I was quoted in a new article on <a href="https://www.politico.com/newsletters/politico-technology-california-decoded-preview/2025/04/18/california-finally-beats-big-tech-in-court-00298056" rel="external nofollow noopener" target="_blank">Politico</a> with my comments about SB 1047 and the need for proportional liability mechanisms.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 14, 2025</th>
                  <td>
                    <a href="https://arxiv.org/abs/2504.09346" rel="external nofollow noopener" target="_blank">“It’s not a representation of me”: Examining Accent Bias and Digital Exclusion in Synthetic AI Voice Services</a> has been accepted as a full paper at <a href="https://facctconference.org/" rel="external nofollow noopener" target="_blank">ACM FAccT 2025</a>! Congratulations to my co-authors Shira Michel, Sufi Kaur, Sarah Elizabeth Gillespie, Jeffrey Gleason, and Dr. Christo Wilson.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 10, 2025</th>
                  <td>
                    New blog post: <a href="https://huggingface.co/blog/evijit/public-org-data-ai" rel="external nofollow noopener" target="_blank">Empowering Public Organizations: Preparing Your Data for the AI Era</a> now out on Hugging Face! In this article, we outline comprehensive guide on transforming public data into AI-ready formats, empowering government agencies, libraries, and nonprofits to maximize their data’s potential for machine learning applications.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Mar 24, 2025</th>
                  <td>
                    My first ever op-ed! <a href="https://www.technologyreview.com/2025/03/24/1113647/why-handing-over-total-control-to-ai-agents-would-be-a-huge-mistake/" rel="external nofollow noopener" target="_blank">Why handing over total control to AI agents would be a huge mistake</a>, with Margaret Mitchell, Sasha Luccioni, and Giada Pistilli is out on MIT Tech Review! In it, we investigate the slow but sure ceding of power and control to increasingly autonomous AI Agents and ask - how much autonomy is too much?
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Mar 23, 2025</th>
                  <td>
                    I was quoted in a new article on <a href="https://www.businessinsider.com/openai-chatgpt-brainstorming-addiction-dependence-negative-consequences-mit-research-2025-3" rel="external nofollow noopener" target="_blank">Business Insider</a> about the hidden costs of reasoning with ChatGPT. I reflect on the common conflation of automation and autonomy.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Mar 19, 2025</th>
                  <td>
                    Some more coverage of our paper on why fully automating agents is a bad idea! I was quoted on this new piece on <a href="https://www.snexplores.org/article/deepseek-ai-reasoning-agents" rel="external nofollow noopener" target="_blank">Science News Explores</a> on Deepseek, Agents, and Open Source.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Mar 14, 2025</th>
                  <td>
                    We submitted <a href="https://huggingface.co/blog/ai-action-wh-2025" rel="external nofollow noopener" target="_blank">Hugging Face’s response</a> to the White House Office of Science and Technology Policy’s request for information on the <a href="https://www.whitehouse.gov/briefings-statements/2025/02/public-comment-invited-on-artificial-intelligence-action-plan/" rel="external nofollow noopener" target="_blank">White House AI Action Plan</a>. We took this opportunity to (re-)assert the fundamental role that open AI systems and open science play in enabling the technology to be more performant and efficient, broadly and reliably adopted, and meeting the highest standards of security. Covered in <a href="https://venturebeat.com/ai/hugging-face-submits-open-source-blueprint-challenging-big-tech-in-white-house-ai-policy-fight/" rel="external nofollow noopener" target="_blank">VentureBeat</a>.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Mar 14, 2025</th>
                  <td>
                    I was incredibly thrilled to speak on a panel on Open Source AI Regulation at the <a href="https://dec.yale.edu/programs/summit-on-state-ai-legislation-ssail" rel="external nofollow noopener" target="_blank">Summit for State AI Legislation (SSAIL) hosted by the Digital Ethics Center, Yale University</a>. We got into the nitty gritty of emergent AI regulation, how it might impact open source in particular, and important considerations going forward.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Mar 13, 2025</th>
                  <td>
                    New paper: <a href="https://arxiv.org/abs/2503.16861" rel="external nofollow noopener" target="_blank">In-House Evaluation Is Not Enough: Towards Robust Third-Party Flaw Disclosure for General-Purpose AI</a>. 34 prominent researchers from industry, academia, civil society, and policy came together draft a proposal for a better, self sustaining system for flaw reporting for AI that involves coordination and transparency from all the actors involved. Covered in <a href="https://www.wired.com/story/ai-researchers-new-system-report-bugs/" rel="external nofollow noopener" target="_blank">Wired</a>.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Mar 8, 2025</th>
                  <td>
                    I spoke on the NLP &amp; Generative AI Panel at the <a href="https://www.linkedin.com/posts/harvard-business-school-tech-club_hbs-generativeai-activity-7301706801954050048-PaR-" rel="external nofollow noopener" target="_blank">Harvard Business School Tech Conference</a>, where I reflected on my work that sits at the intersection of technology, ethics and policy. We talked policy at Hugging Face, Chinese LLMs and more!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb 25, 2025</th>
                  <td>
                    We submitted <a href="https://huggingface.co/datasets/huggingface/policy-docs/resolve/main/2025_UK_Govt_Consultation_Copyright_and_Artificial_Intelligence.pdf" rel="external nofollow noopener" target="_blank">Hugging Face’s response to the United Kingdom Intellectual Property Office’s Open Consultation on Copyright and AI</a>. We continue to champion data transparency mechanisms and standardized opt-outs, and we contend that TDM exceptions are required for research orgs and small open source developers to do important work.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb 23, 2025</th>
                  <td>
                    I was quoted on a <a href="https://www.businessinsider.com/ai-agents-jobs-board-ad-replacing-human-skills-2025-2" rel="external nofollow noopener" target="_blank">Business Insider article</a> on AI Agents and Job Boards. I push back against conflating autonomy with agency, and point out that agents with human oversight will augment, not replace, human workers.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb 19, 2025</th>
                  <td>
                    New article - I spoke to <a href="https://www.techcircle.in/2025/02/19/why-truly-open-source-ai-remains-out-of-reach" rel="external nofollow noopener" target="_blank">TechCircle India</a> on the harms of Open washing and better open standards! We also talked about Hugging Face’s open reproduction of DeepSeek R1.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb 17, 2025</th>
                  <td>
                    New paper - <a href="https://huggingface.co/papers/2502.12447" rel="external nofollow noopener" target="_blank">Protecting Human Cognition in the Age of AI</a> with Anjali Singh, Karan Taneja and Klara Guan - accepted at the <a href="https://ai-tools-for-thought.github.io/workshop/" rel="external nofollow noopener" target="_blank">Tools for Thought Workshop</a> at <a href="https://chi2025.acm.org/" rel="external nofollow noopener" target="_blank">CHI 2025!</a> In this work, we claim that overreliance on Generative AI models disrupt traditional learning pathways and suggest best practices for better teaching, testing, and learning tools to restore these paths.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb 7, 2025</th>
                  <td>
                    I spoke on a panel called “Concrete Applications of AI” at the MIT Sloan School of Management AI Conference. I discussed the broken AI Harm reporting landscape, the importance of evals, safe harbors, structured and coordinated disclosure processes, and our proposed framework (<a href="https://arxiv.org/abs/2402.07039" rel="external nofollow noopener" target="_blank">Coordinated AI Flaws Disclosure</a>) as a path forward.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb 7, 2025</th>
                  <td>
                    New paper! <a href="https://arxiv.org/abs/2502.03689" rel="external nofollow noopener" target="_blank">Stop treating “AGI” as the north-star goal of AI research</a>. In this paper, co authored with a group of incredible scholars, we posit that “AGI” is as nebulous to define as its supposed benefits, and we argue that principled scientific, engineering and societal needs should drive AI research instead.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb 4, 2025</th>
                  <td>
                    New blog post: <a href="https://huggingface.co/blog/evijit/smollm-deepseek-bias-eval" rel="external nofollow noopener" target="_blank">Smol but Mighty: Can Small Models Reason well? 🤔</a> now out on Hugging Face! In this article, I show that “Smol” (less than 2B parameters) language models pack impressive performance, competing with models several orders of magnitudes better from last year. I also find that Chinese-developed models (Deepseek R1, Qwen) exhibiting distinctly different cultural biases than American models.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Feb 4, 2025</th>
                  <td>
                    New paper with Margaret Mitchell, Sasha Luccioni and Giada Pistilli - <a href="https://huggingface.co/papers/2502.02649" rel="external nofollow noopener" target="_blank">Fully Autonomous AI Agents Should Not be Developed</a>. In this paper, we argue from a purely value laden perspective, with increasing autonomy, the values that people care about will start breaking down. Some level of human control needs to always be in place.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 24, 2025</th>
                  <td>
                    Another article with my comments about <a href="https://openai.com/index/announcing-the-stargate-project/" rel="external nofollow noopener" target="_blank">Stargate</a>! New article on <a href="https://www.businessinsider.com/openai-stargate-project-moat-deepseek-2025-1" rel="external nofollow noopener" target="_blank">Business Insider</a> where I talk about competitive hardware moats. I reject the false premise of compute = utility.  Teams like Deepseek have made remarkable progress creatively with less resources, and this type of progress will only be more possible by openness and collaboration!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 22, 2025</th>
                  <td>
                    <a href="https://fortune.com/2025/01/22/openai-stargate-ai-sam-altman-donald-trump/" rel="external nofollow noopener" target="_blank">New article on Fortune</a> with my comments about <a href="https://openai.com/index/announcing-the-stargate-project/" rel="external nofollow noopener" target="_blank">Stargate</a>. I talked about the importance of public AI infrastructure, the concentration of power, and the need for openness to counter that, as well as how this mad dash for AGI can actively siphon away resources from issues that can be solved with technology in the present.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 13, 2025</th>
                  <td>
                    The newest Ethics and Society Newsletter: <a href="https://huggingface.co/blog/ethics-soc-7" rel="external nofollow noopener" target="_blank">AI Agents Are Here. What Now?</a> is out! Had a lot of fun writing this with my colleagues: Margaret Mitchell, Giada Pistilli and Sasha Luccioni. Our analyses found that there’s a spectrum of “agent”-ness, and that safety is a key issue, leading to many other value-based concerns.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 3, 2025</th>
                  <td>
                    My <a href="https://evijit.io/assets/img/Epaper_194_2025-01-03_9.jpeg" rel="external nofollow noopener" target="_blank">column with predictions for AI in 2025 - in India and Globally</a> - is out in the <a href="https://www.bhaskar.com/" rel="external nofollow noopener" target="_blank">Dainik Bhaskar</a> in Hindi, Marathi and Gujarati!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Dec 18, 2024</th>
                  <td>
                    <a href="https://arxiv.org/abs/2406.04231" rel="external nofollow noopener" target="_blank">“Quantifying Misalignment Between Agents: Towards a Sociotechnical Understanding of Alignment,”</a> with Aidan Kierans, Hananel Hazan, and Shiri Dori-Hacohen, has been accepted at the Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI-25)!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Dec 15, 2024</th>
                  <td>
                    I was happy to contribute to a Institute for Security and Technology report on <a href="https://securityandtechnology.org/virtual-library/reports/navigating-ai-compliance-part-1/" rel="external nofollow noopener" target="_blank">Navigating AI Compliance via tracing failure patterns from history</a>, led by 
Mariami Tkeshelashvili and Tiffany Saade. The report examines past compliance failures in other industries and how we can apply the lessons learned to AI Governance.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Nov 27, 2024</th>
                  <td>
                    The accepted tiny papers for our Neurips 2024 <a href="https://evaleval.github.io/" rel="external nofollow noopener" target="_blank">Evaluating Evaluations: Examining Best Practices for Measuring Broader Impacts of Generative AI (EvalEval) Workshop</a> are out! Read them <a href="https://evaleval.github.io/accepted-papers.html" rel="external nofollow noopener" target="_blank">here.</a> Congrats to the authors and looking forward to the workshop!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Nov 14, 2024</th>
                  <td>
                    <a href="https://arxiv.org/abs/2410.12104" rel="external nofollow noopener" target="_blank">“To Err is AI : A Case Study Informing LLM Flaw Reporting Practices,”</a> with Sean McGregor, Allyson Ettinger, Nick Judd, Paul Albee, Liwei Jiang, Kavel Rao, Will Smith, Shayne Longpre, Christopher Fiorelli, Michelle Hoang, Sven Cattell, and Nouha Dziri, has been accepted at the Thirty-Seventh Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-25)!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Oct 15, 2024</th>
                  <td>
                    I was quoted on another <a href="https://www.wired.com/story/emteq-smart-glasses-read-emotions-watch-what-you-eat/" rel="external nofollow noopener" target="_blank">WIRED</a> article on emotion detecting glasses, where I point out that mainstream emotion detection tech could be a path to doom if implemented without considering its pitfalls and impact on human agency.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Sep 13, 2024</th>
                  <td>
                    <a href="https://arxiv.org/abs/2409.08135" rel="external nofollow noopener" target="_blank">“Reducing Population-level Inequality Can Improve Demographic Group Fairness: a Twitter Case Study,”</a> with Tomo Lazovich, Kristian Lum, and Christo Wilson, has been accepted at the FAccTRec Workshop at ACM RecSys 2024!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Sep 6, 2024</th>
                  <td>
                    I led <a href="https://huggingface.co/datasets/huggingface/policy-docs/resolve/main/2024_AISI_Dual_Use_Foundational_Models_Response.pdf" rel="external nofollow noopener" target="_blank">Hugging Face’s response to the RFC on AI 800-1: Managing Misuse Risk for Dual-Use Foundational Models</a>, highlighting ways to protect the open source AI ecosystem while creating effective safety practices to manage the risks of dual-use foundational models.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Aug 28, 2024</th>
                  <td>
                    I was quoted on a new <a href="https://www.wired.com/story/plaud-note-pin-ai-wearable/" rel="external nofollow noopener" target="_blank">WIRED</a> article on Wearable AI devices. I talk about hallucinations, overreliance and the additional hurdles people with non Western accents often face while interacting with such devices.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Aug 22, 2024</th>
                  <td>
                    Truly open-source AI should include not just model weights but also training data, code, and thorough documentation. <a href="https://opensource.org/" rel="external nofollow noopener" target="_blank">Open Source Initiative</a> has a new definition of Open-Source AI, and I got to talk to <a href="https://www.technologyreview.com/2024/08/22/1097224/we-finally-have-a-definition-for-open-source-ai/" rel="external nofollow noopener" target="_blank">MIT Tech Review</a> about it!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Aug 21, 2024</th>
                  <td>
                    I commented on a <a href="https://www.lesechos.fr/tech-medias/intelligence-artificielle/en-californie-la-loi-de-protection-contre-lia-amendee-pour-apaiser-la-silicon-valley-2114566" rel="external nofollow noopener" target="_blank">Les Echos article</a> about SB 1047, a new California AI regulation currently up for vote. I raised concerns about potential chilling effects on the open source AI ecosystem due to the bill.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Aug 12, 2024</th>
                  <td>
                    I was quoted in a new <a href="https://fortune.com/2024/08/12/defcon-gen-ai-bug-bounty-cybersecurity-vulnerabilities/?987123" rel="external nofollow noopener" target="_blank">Fortune Magazine article</a> on DEF CON 2024, talking about our push towards structured harm reporting in AI. DEF CON and AI Village this year was a resounding success, and I am looking forward to having more of these conversations with practitioners, civil society and policymakers towards greater transparency!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Aug 1, 2024</th>
                  <td>
                    Excited to announce our NeurIPS 2024 Workshop, <a href="https://evaleval.github.io/" rel="external nofollow noopener" target="_blank">“Evaluating Evaluations: Examining Best Practices for Measuring Broader Impacts of Generative AI” aka EvalEval 2024!</a>. Evaluation is an important governance tool; if sufficiently grounded, defined, and motivated by the needs of affected parties. See you at NeurIPS!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jul 18, 2024</th>
                  <td>
                    My paper: <a href="https://arxiv.org/abs/2402.07039" rel="external nofollow noopener" target="_blank">Coordinated Flaws Disclosure for AI: Beyond Security Vulnerabilities</a> with Sven Cattell and Lucie-Aimée Kafee was accepted at AIES 2024! We describe the current landscape of disclosure, the need for extension of model cards towards intent and scope, and propose a framework to disclose AI flaws including independent adjudication.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jul 17, 2024</th>
                  <td>
                    Very happy to see my <a href="https://evijit.io/assets/img/Epaper_194_2024-07-17_13.jpeg" rel="external nofollow noopener" target="_blank">column about AI Ethics in India on today’s Dainik Bhaskar</a>. It is the largest Hindi Daily newspaper in India and being able to talk about the unique challenges of AI in the Indian context to such a wide audience means a lot to me! 🙂
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jun 2, 2024</th>
                  <td>
                    I am excited to share my first ever policy response - <a href="https://huggingface.co/datasets/huggingface/policy-docs/resolve/main/2024_NIST_GENAI_Response.pdf" rel="external nofollow noopener" target="_blank">Hugging Face’s response to the NIST RFC on AI 600-1: Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile</a>! Thanks a ton to my manager/mentor duo Irene Solaiman and Yacine Jernite for walking me through this massive effort!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 28, 2024</th>
                  <td>
                    I was quoted in a new article at <a href="https://www.fastcompany.com/91131154/image-search-results-bias-research" rel="external nofollow noopener" target="_blank">Fast Company</a> about our work in finding demographic biases in Google and Bing image search with real user queries!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 25, 2024</th>
                  <td>
                    I had a lot of fun speaking at the <a href="https://www.linkedin.com/feed/update/urn:li:activity:7190859597044236288/" rel="external nofollow noopener" target="_blank">AI Bias and Ethics panel organized by Out in Tech and MassChallenge</a>. It was great to interact with the thriving queer tech community in the Boston area and highlight important issues of discrimination and social justice issues in AI and tech in general.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 22, 2024</th>
                  <td>
                    I participated in a closed door AI and Copyright Law workshop at Harvard Law School called Transform Copyright, where I represented Hugging Face and forwarded the cause of open source, democratic AI.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 8, 2024</th>
                  <td>
                    My collaborative art piece, <a href="https://huggingface.co/spaces/evijit/BecauseOfYou" rel="external nofollow noopener" target="_blank">“Because of You”</a> with Eryk Salvaggio, just got accepted to the <a href="https://cvpr.thecvf.com/Conferences/2024/CallForAIArt" rel="external nofollow noopener" target="_blank">CVPR 2024 AI Art Gallery!</a>
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Mar 16, 2024</th>
                  <td>
                    My comments on covert racial bias in LLMs appeared in articles at <a href="https://www.technologyreview.com/2024/03/11/1089683/llms-become-more-covertly-racist-with-human-intervention/" rel="external nofollow noopener" target="_blank">MIT Technology Review</a> and <a href="https://www.theguardian.com/technology/2024/mar/16/ai-racism-chatgpt-gemini-bias" rel="external nofollow noopener" target="_blank">The Guardian</a>.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 23, 2024</th>
                  <td>
                    <a href="https://dl.acm.org/doi/10.1145/3589334.3645666" rel="external nofollow noopener" target="_blank">“Perceptions in pixels: analyzing perceived gender and skin tone in real-world image search results”</a> has been accepted as a full paper at WWW 2024! Congratulations to my co-authors Jeffrey Gleason, Dr. Ronald E. Robertson and Dr. Christo Wilson.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jan 12, 2024</th>
                  <td>
                    I had the distinct honor of moderating and participating in a panel of experts, talking to Congressional staffers and cybersecurity professionals, at the AI Vulnerability Reporting event organized by Hackers on the Hill (HotH), with support from AI Village and AI Vulnerability Database/ARVA!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Oct 12, 2023</th>
                  <td>
                    I was featured on <a href="https://www.indiatimes.com/trending/spectrum/how-can-ai-affect-queer-people-in-india-617408.html" rel="external nofollow noopener" target="_blank">IndiaTimes</a>, where I talked about India-specific issues that Queer people might face in the current landscape of generative AI.
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Aug 10, 2023</th>
                  <td>
                    I was excited to be involved with the AI Village DC and partners at <a href="https://defcon.org/" rel="external nofollow noopener" target="_blank">DEF CON 2023</a> to help organize the largest-ever public <a href="http://aivillage.org/generative\%20red\%20team/generative-red-team/" rel="external nofollow noopener" target="_blank">Generative AI Red Teaming challenge!</a>. Myself, along with several other attendees and organizers were mentioned in <a href="https://www.nytimes.com/2023/08/16/technology/ai-defcon-hackers.html?unlocked_article_code=QqiwO9KZ2dVgz77qvZdn_d0wtUydJlP-OxRmVpvYSxD6eVdiBnfwRKqn1kO498M75VY8xZfH-ryaJPdxX_fK70oQSiJN8_scGieCDMEqiEbg8IC2MFaCMFR8FOY3m1D2X8mRWLKhsEOOgzEoV7trJnskK6IXwrE1ijhwGrzhGlOaMrRT4VP2SXcKMY0WthVTKhXLuYkuTOom8KYrWJgxS8ORjfNqxcnBsA8Br7mCacRlGSG2ryt1rnpiQl_i9fnN5Pso-i1XUnmAHSlWhiGW_QxSMr0cTx0UOn1jiYN4sXJRzbHK86kgKN5CGfdScuOPVh1vD5hUwSeuCBvhlPaxfJLhx1E1V6FG3q4Jp3e_mqkHisCW8wfKqWWN0co-Gy0Q4dKsZHsZeg" rel="external nofollow noopener" target="_blank">the New York Times</a> and <a href="https://www.forbes.com/sites/rashishrivastava/2023/09/01/ai-red-teams-google-nvidia-microsoft-meta/?sh=1f57fb4a6627" rel="external nofollow noopener" target="_blank">Forbes</a>!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Jun 15, 2023</th>
                  <td>
                    “Queer In AI: A Case Study in Community-Led Participatory AI” received <a href="https://evijit.io/assets/pdf/FAccTBestPaperAward.pdf" rel="external nofollow noopener" target="_blank">BEST PAPER</a> award at <a href="https://facctconference.org/2023/index.html" rel="external nofollow noopener" target="_blank">ACM FAccT 2023!</a> Congratulations QueerInAI!
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">May 5, 2023</th>
                  <td>
                    Paper: “When Fair Classification Meets Noisy Protected Attributes” accepted at <a href="https://www.aies-conference.com/2023/" rel="external nofollow noopener" target="_blank">AIES 2023!</a>
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 10, 2023</th>
                  <td>
                    Two CRAFT proposals: <a href="https://sites.google.com/view/raiindiacraftfacct2023/home" rel="external nofollow noopener" target="_blank">“Towards an India-first Responsible AI research agenda”</a>, and <a href="https://www.aqai.xyz/acm-facct-craft-workshop-2023/" rel="external nofollow noopener" target="_blank">“Humanitarian AI for the Global South”</a> accepted at <a href="https://facctconference.org/2023/index.html" rel="external nofollow noopener" target="_blank">ACM FAccT 2023!</a>
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Apr 7, 2023</th>
                  <td>
                    Paper: “Queer In AI: A Case Study in Community-Led Participatory AI” accepted at <a href="https://facctconference.org/2023/index.html" rel="external nofollow noopener" target="_blank">ACM FAccT 2023!</a>
 
                  </td>
                </tr> 
                <tr>
                  <th scope="row">Mar 12, 2023</th>
                  <td>
                    I’m speaking at SXSW 2023 in Austin! Talk title: <a href="https://schedule.sxsw.com/2023/events/PP122773" rel="external nofollow noopener" target="_blank">Can There Be AI Art Without An Artist?</a>
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>


          <br>

          <!-- Selected papers -->
          

          <div class="contact-note" style="text-align: center; font-size: small;">
            The best way to reach me is via email. I am also frequently active on X/Twitter.
          </div>


        </article>

      </div>
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0" style="text-align: center;">
        © Copyright 2025 Avijit Ghosh  . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.
Last updated: September 30, 2025.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-86SL91SN45"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-86SL91SN45');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    <div id="buttonmodal">
    <div class="newmodal">
        <h5>Email Options</h5>
        <ul>
        <li>
<a href="mailto:avijit@huggingface.co" title="email">avijit@huggingface.co</a>(HF)</li>
        <li>
<a href="mailto:avijit.g@uconn.edu" title="email">avijit.g@uconn.edu</a>(UConn)</li>
        <li>
<a href='mailto:avijitg22@gmail.com"' title="email">avijitg22@gmail.com</a>(Personal)</li>
        </ul>
    </div>
</div>

<script>
    var elements = document.querySelectorAll('a.buttonmodal');
    elements.forEach(element => {
        element.addEventListener('click', function(event) {
            event.preventDefault();
            event.stopPropagation();
            document.getElementById('buttonmodal').style.display = 'flex';
        });
    });
    document.getElementById('buttonmodal').addEventListener('click', function(event) {
        if(event.target.closest('.newmodal')) return; 
        document.getElementById('buttonmodal').style.display = 'none';
    });
</script>

<style>
    #buttonmodal {display: none; position: fixed; background: rgba(0,0,0,0.7); left: 0; top: 0; width: 100%; height: 100vh; justify-content: center; align-items: center; z-index: 99999;}
    #buttonmodal .newmodal {max-width: 20rem; width: 100%; background:  var(--global-bg-color); border-radius: 5px; padding: 1.75rem 1.25rem; display: flex;}
    #buttonmodal .newmodal h3 {padding: 0 0 0.5rem;}
    #buttonmodal .newmodal ul {margin: 0;}
    #buttonmodal .newmodal ul li {list-style: none; display: block; margin: 0.25rem 0;}
    #buttonmodal .newmodal ul li a {display: block;}
</style>

  </body>
</html>
